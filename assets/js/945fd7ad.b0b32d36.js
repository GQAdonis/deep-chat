"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[5877],{5162:(e,t,n)=>{n.d(t,{Z:()=>i});var a=n(7294),r=n(6010);const o={tabItem:"tabItem_Ymn6"};function i(e){let{children:t,hidden:n,className:i}=e;return a.createElement("div",{role:"tabpanel",className:(0,r.Z)(o.tabItem,i),hidden:n},t)}},4866:(e,t,n)=>{n.d(t,{Z:()=>T});var a=n(7462),r=n(7294),o=n(6010),i=n(2466),s=n(6550),l=n(1980),p=n(7392),u=n(12);function m(e){return function(e){return r.Children.map(e,(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:r}}=e;return{value:t,label:n,attributes:a,default:r}}))}function c(e){const{values:t,children:n}=e;return(0,r.useMemo)((()=>{const e=t??m(n);return function(e){const t=(0,p.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function d(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function h(e){let{queryString:t=!1,groupId:n}=e;const a=(0,s.k6)(),o=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,l._X)(o),(0,r.useCallback)((e=>{if(!o)return;const t=new URLSearchParams(a.location.search);t.set(o,e),a.replace({...a.location,search:t.toString()})}),[o,a])]}function k(e){const{defaultValue:t,queryString:n=!1,groupId:a}=e,o=c(e),[i,s]=(0,r.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!d({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:o}))),[l,p]=h({queryString:n,groupId:a}),[m,k]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[a,o]=(0,u.Nk)(n);return[a,(0,r.useCallback)((e=>{n&&o.set(e)}),[n,o])]}({groupId:a}),b=(()=>{const e=l??m;return d({value:e,tabValues:o})?e:null})();(0,r.useLayoutEffect)((()=>{b&&s(b)}),[b]);return{selectedValue:i,selectValue:(0,r.useCallback)((e=>{if(!d({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);s(e),p(e),k(e)}),[p,k,o]),tabValues:o}}var b=n(2389);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function y(e){let{className:t,block:n,selectedValue:s,selectValue:l,tabValues:p}=e;const u=[],{blockElementScrollPositionUntilNextRender:m}=(0,i.o5)(),c=e=>{const t=e.currentTarget,n=u.indexOf(t),a=p[n].value;a!==s&&(m(t),l(a))},d=e=>{let t=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const n=u.indexOf(e.currentTarget)+1;t=u[n]??u[0];break}case"ArrowLeft":{const n=u.indexOf(e.currentTarget)-1;t=u[n]??u[u.length-1];break}}t?.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":n},t)},p.map((e=>{let{value:t,label:n,attributes:i}=e;return r.createElement("li",(0,a.Z)({role:"tab",tabIndex:s===t?0:-1,"aria-selected":s===t,key:t,ref:e=>u.push(e),onKeyDown:d,onClick:c},i,{className:(0,o.Z)("tabs__item",g.tabItem,i?.className,{"tabs__item--active":s===t})}),n??t)})))}function x(e){let{lazy:t,children:n,selectedValue:a}=e;const o=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=o.find((e=>e.props.value===a));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},o.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==a}))))}function f(e){const t=k(e);return r.createElement("div",{className:(0,o.Z)("tabs-container",g.tabList)},r.createElement(y,(0,a.Z)({},e,t)),r.createElement(x,(0,a.Z)({},e,t)))}function T(e){const t=(0,b.Z)();return r.createElement(f,(0,a.Z)({key:String(t)},e))}},7235:(e,t,n)=>{n.d(t,{Z:()=>r});var a=n(7294);function r(){return a.createElement("div",{style:{height:"1px"}})}},8751:(e,t,n)=>{n.d(t,{Z:()=>o,a:()=>r});var a=n(7294);function r(e){return e?.children[0]?.children[0]}function o(e){let{children:t,minHeight:n}=e;return a.createElement("div",{className:"documentation-example-container",style:{minHeight:`${n||400}px`}},a.createElement("div",null,t))}},9146:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>h,contentTitle:()=>c,default:()=>y,frontMatter:()=>m,metadata:()=>d,toc:()=>k});var a=n(7462),r=(n(7294),n(3905)),o=n(8751),i=n(4602),s=n(7235),l=n(1262),p=n(5162),u=n(4866);const m={sidebar_position:7},c="Speech",d={unversionedId:"docs/speech",id:"docs/speech",title:"Speech",description:"textToSpeech",source:"@site/docs/docs/speech.mdx",sourceDirName:"docs",slug:"/docs/speech",permalink:"/docs/speech",draft:!1,editUrl:"https://github.com/OvidijusParsiunas/deep-chat/tree/main/website/docs/docs/speech.mdx",tags:[],version:"current",sidebarPosition:7,frontMatter:{sidebar_position:7},sidebar:"docs",previous:{title:"Message Styles",permalink:"/docs/messageStyles"},next:{title:"Files",permalink:"/docs/files"}},h={},k=[{value:"<code>textToSpeech</code>",id:"textToSpeech",level:3},{value:"Example",id:"example",level:4},{value:"<code>speechToText</code>",id:"speechToText",level:3},{value:"Example",id:"example-1",level:4},{value:"Types",id:"types",level:2},{value:"<code>WebSpeechOptions</code>",id:"WebSpeechOptions",level:3},{value:"Example",id:"example-2",level:4},{value:"<code>AzureOptions</code>",id:"AzureOptions",level:3},{value:"Example",id:"example-3",level:4},{value:"Retrieve token example",id:"retrieve-token-example",level:4},{value:"<code>TextColor</code>",id:"TextColor",level:3},{value:"Example",id:"example-4",level:4},{value:"<code>Commands</code>",id:"Commands",level:3},{value:"Example",id:"example-5",level:4},{value:"<code>ButtonStyles</code>",id:"ButtonStyles",level:3},{value:"Example",id:"example-6",level:4},{value:"Demo",id:"demo",level:2}],b={toc:k},g="wrapper";function y(e){let{components:t,...m}=e;return(0,r.kt)(g,(0,a.Z)({},b,m,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"speech"},"Speech"),(0,r.kt)("video",{className:"documentation-video",controls:!0},(0,r.kt)("source",{src:"https://github.com/OvidijusParsiunas/deep-chat/assets/18709577/e103a42e-b3a7-4449-b9db-73fed6d7876e"})),(0,r.kt)("h3",{id:"textToSpeech"},(0,r.kt)("inlineCode",{parentName:"h3"},"textToSpeech")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Type: ",(0,r.kt)("inlineCode",{parentName:"li"},"true")," | {",(0,r.kt)("br",null),"\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"li"},"voiceName?: string"),", ",(0,r.kt)("br",null),"\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"li"},"lang?: string"),", ",(0,r.kt)("br",null),"\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"li"},"pitch?: number"),", ",(0,r.kt)("br",null),"\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"li"},"rate?: string"),", ",(0,r.kt)("br",null),"\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"li"},"volume?: number")," ",(0,r.kt)("br",null),"\n}")),(0,r.kt)("p",null,"When the chat receives a new text message - your device will automatically be read out. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"voiceName")," is the name of the voice that will be used to read out the incoming message. Please note that different Operating Systems\nsupport different voices. Use the following code snippet to see the available voices for your device: ",(0,r.kt)("inlineCode",{parentName:"p"},"window.speechSynthesis.getVoices()")," ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"lang")," is used to set the utterance language. See the following ",(0,r.kt)("a",{parentName:"p",href:"https://stackoverflow.com/questions/23733537/what-are-the-supported-languages-for-web-speech-api-in-html5"},(0,r.kt)("inlineCode",{parentName:"a"},"QA"))," for the available options. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"pitch")," sets the pitch at which the utterance will be spoken at. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"volume")," set the volume at which the utterance will be spoken at."),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"Text to speech is using ",(0,r.kt)("a",{parentName:"p",href:"https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesis"},(0,r.kt)("inlineCode",{parentName:"a"},"SpeechSynthesis"))," Web API\nwhich is supported differently across different devices.")),(0,r.kt)(l.Z,{mdxType:"BrowserOnly"},(()=>n(1853).readdAutoNavShadowToggle())),(0,r.kt)("h4",{id:"example"},"Example"),(0,r.kt)(o.Z,{mdxType:"ComponentContainer"},(0,r.kt)(i.Z,{directConnection:{demo:!0},introMessage:"Send a message to hear the response.",containerStyle:{borderRadius:"8px"},textToSpeech:{volume:.9},mdxType:"DeepChatBrowser"})),(0,r.kt)(u.Z,{mdxType:"Tabs"},(0,r.kt)(p.Z,{value:"js",label:"Sample code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'<deep-chat textToSpeech=\'{"volume": "0.9"}\'></deep-chat>\n'))),(0,r.kt)(p.Z,{value:"py",label:"Full code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  textToSpeech=\'{"volume": "0.9"}\'\n  introMessage="Send a message to hear the response."\n  containerStyle=\'{"borderRadius": "8px"}\'\n  directConnection=\'{"demo": true}\'\n></deep-chat>\n')))),(0,r.kt)(s.Z,{mdxType:"LineBreak"}),(0,r.kt)("h3",{id:"speechToText"},(0,r.kt)("inlineCode",{parentName:"h3"},"speechToText")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Type: ",(0,r.kt)("inlineCode",{parentName:"p"},"true")," | {",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"p"},"webSpeech?:")," ",(0,r.kt)("inlineCode",{parentName:"p"},"true")," | ",(0,r.kt)("a",{parentName:"p",href:"#WebSpeechOptions"},(0,r.kt)("inlineCode",{parentName:"a"},"WebSpeechOptions")),", ",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("a",{parentName:"p",href:"#AzureOptions"},(0,r.kt)("inlineCode",{parentName:"a"},"azure?: AzureOptions")),", ",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("a",{parentName:"p",href:"#TextColor"},(0,r.kt)("inlineCode",{parentName:"a"},"textColor?: TextColor")),", ",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"p"},"displayInterimResults?: boolean"),", ",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"p"},"stopAfterSilenceMs?: number"),", ",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"p"},"translations?: {[key: string]: string}"),", ",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("a",{parentName:"p",href:"#Commands"},(0,r.kt)("inlineCode",{parentName:"a"},"commands?: Commands")),", ",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("a",{parentName:"p",href:"#ButtonStyles"},(0,r.kt)("inlineCode",{parentName:"a"},"button?: ButtonStyles"))," ",(0,r.kt)("br",null),"\n}")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Default: ",(0,r.kt)("em",{parentName:"p"},"{webSpeech: true, stopAfterSilenceMs: 25000 (25 seconds)}")))),(0,r.kt)("p",null,"Transcribe your voice into text and control chat with commands.",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"webSpeech")," utilises ",(0,r.kt)("a",{parentName:"p",href:"https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API"},(0,r.kt)("inlineCode",{parentName:"a"},"Web Speech API"))," to transcribe your speech. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"azure")," utilises ",(0,r.kt)("a",{parentName:"p",href:"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-to-text"},(0,r.kt)("inlineCode",{parentName:"a"},"Azure Cognitive Speech Services API"))," to transcribe your speech. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"textColor")," is used to set the color of interim and final results text. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"displayInterimResults")," controls whether interim results are displayed. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"stopAfterSilenceMs")," is the milliseconds of silence required for the microphone to automatically turn off. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"translations")," is a case-sensitive one-to-one mapping of words that will automatically be translated to others. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"commands")," is used to set the phrases that will trigger various chat functionality. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"button")," defines the styling used for the microphone button."),(0,r.kt)("h4",{id:"example-1"},"Example"),(0,r.kt)(o.Z,{mdxType:"ComponentContainer"},(0,r.kt)(i.Z,{directConnection:{demo:!0},introMessage:"Click the microphone to start transcribing your speech.",containerStyle:{borderRadius:"8px"},speechToText:{webSpeech:!0,stopAfterSilenceMs:5e3,translations:{hello:"goodbye",Hello:"Goodbye"},commands:{resume:"resume",settings:{commandMode:"hello"}},button:{position:"outside-left"}},mdxType:"DeepChatBrowser"})),(0,r.kt)(u.Z,{mdxType:"Tabs"},(0,r.kt)(p.Z,{value:"js",label:"Sample code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'<deep-chat\n  speechToText=\'{\n    "webSpeech": true,\n    "stopAfterSilenceMs": 5000,\n    "translations": {"hello": "goodbye", "Hello": "Goodbye"},\n    "commands": {"resume": "resume", "settings": {"commandMode": "hello"}},\n    "button": {"position": "outside-left"}\n  }\'\n></deep-chat>\n'))),(0,r.kt)(p.Z,{value:"py",label:"Full code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  speechToText=\'{\n    "webSpeech": true,\n    "stopAfterSilenceMs": 5000,\n    "translations": {"hello": "goodbye", "Hello": "Goodbye"},\n    "commands": {"resume": "resume", "settings": {"commandMode": "hello"}},\n    "button": {"position": "outside-left"}\n  }\'\n  introMessage="Click the microphone to start transcribing your speech."\n  containerStyle=\'{"borderRadius": "8px"}\'\n  directConnection=\'{"demo": true}\'\n></deep-chat>\n')))),(0,r.kt)(s.Z,{mdxType:"LineBreak"}),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"If the ",(0,r.kt)("a",{parentName:"p",href:"./files#microphone"},(0,r.kt)("inlineCode",{parentName:"a"},"microphone"))," recorder is set - this will not be enabled. ",(0,r.kt)("br",null))),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"Speech to text functionality is provided by the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/OvidijusParsiunas/speech-to-element"},(0,r.kt)("inlineCode",{parentName:"a"},"speech to element"))," library.")),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"Support for ",(0,r.kt)("inlineCode",{parentName:"p"},"webSpeech")," varies across different browsers, please check the ",(0,r.kt)("a",{parentName:"p",href:"https://caniuse.com/?search=Web%20Speech%20API"},(0,r.kt)("inlineCode",{parentName:"a"},"Can I use"))," Speech Recognition API section.\n(The yellow bars indicate that it is supported)")),(0,r.kt)(s.Z,{mdxType:"LineBreak"}),(0,r.kt)("h2",{id:"types"},"Types"),(0,r.kt)("p",null,"Object types for ",(0,r.kt)("a",{parentName:"p",href:"#speechToText"},(0,r.kt)("inlineCode",{parentName:"a"},"speechToText")),":"),(0,r.kt)("h3",{id:"WebSpeechOptions"},(0,r.kt)("inlineCode",{parentName:"h3"},"WebSpeechOptions")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Type: {",(0,r.kt)("inlineCode",{parentName:"li"},"language?: string"),"}")),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"language")," is used to set the recognition language. See the following ",(0,r.kt)("a",{parentName:"p",href:"https://stackoverflow.com/questions/23733537/what-are-the-supported-languages-for-web-speech-api-in-html5"},(0,r.kt)("inlineCode",{parentName:"a"},"QA")),"\nfor the full list."),(0,r.kt)("p",null,"// WORK - test error handling if incorrect"),(0,r.kt)("h4",{id:"example-2"},"Example"),(0,r.kt)(o.Z,{mdxType:"ComponentContainer"},(0,r.kt)(i.Z,{directConnection:{demo:!0},introMessage:"Click the microphone to start transcribing your speech.",containerStyle:{borderRadius:"8px"},speechToText:{webSpeech:{language:"en-US"}},mdxType:"DeepChatBrowser"})),(0,r.kt)(u.Z,{mdxType:"Tabs"},(0,r.kt)(p.Z,{value:"js",label:"Sample code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'<deep-chat speechToText=\'{"webSpeech": {"language": "en-US"}}\'></deep-chat>\n'))),(0,r.kt)(p.Z,{value:"py",label:"Full code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  speechToText=\'{"webSpeech": {"language": "en-US"}}\'\n  introMessage="Click the microphone to start transcribing your speech."\n  containerStyle=\'{"borderRadius": "8px"}\'\n  directConnection=\'{"demo": true}\'\n></deep-chat>\n')))),(0,r.kt)(s.Z,{mdxType:"LineBreak"}),(0,r.kt)("h3",{id:"AzureOptions"},(0,r.kt)("inlineCode",{parentName:"h3"},"AzureOptions")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Type: {",(0,r.kt)("br",null),"\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"li"},"region: string"),", ",(0,r.kt)("br",null),"\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"li"},"retrieveToken?: () => Promise<string>"),", ",(0,r.kt)("br",null),"\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"li"},"subscriptionKey?: string"),", ",(0,r.kt)("br",null),"\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"li"},"token?: string"),", ",(0,r.kt)("br",null),"\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"li"},"language?: string")," ",(0,r.kt)("br",null),"\n}")),(0,r.kt)("p",null,"This object requires ",(0,r.kt)("inlineCode",{parentName:"p"},"region")," and either ",(0,r.kt)("inlineCode",{parentName:"p"},"retrieveToken"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"subscriptionKey")," or the ",(0,r.kt)("inlineCode",{parentName:"p"},"token")," properties: ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"region")," is the location/region of your speech resource. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"retrieveToken")," is a function used to retrieve a new token for the Azure speech resource. It is the recommended property to use as\nit can retrieve the token from a secure server that will hide your credentials. Check out the ",(0,r.kt)("a",{parentName:"p",href:"#retrieve-token-example"},"retrieval example")," below\nand ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/OvidijusParsiunas/speech-to-element/tree/main/examples"},"starter server templates"),". ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"subscriptionKey")," is the subscription key for the Azure speech resource. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"token")," is a temporary token for the Azure speech resource. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"language")," is a BCP-47 string value to denote the language of the recognition. You cand find the full\nlist ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/azure/cognitive-services/speech-service/supported-languages"},"here"),". ",(0,r.kt)("br",null)),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"To use the Azure Speech To Text service - please add the ",(0,r.kt)("a",{parentName:"p",href:"https://www.npmjs.com/package/microsoft-cognitiveservices-speech-sdk"},(0,r.kt)("inlineCode",{parentName:"a"},"Speech SDK"))," to your project.\nSee ",(0,r.kt)("a",{parentName:"p",href:"../examples/externalModules"},"EXAMPLES"),".")),(0,r.kt)("h4",{id:"example-3"},"Example"),(0,r.kt)(o.Z,{mdxType:"ComponentContainer"},(0,r.kt)(i.Z,{directConnection:{demo:!0},introMessage:"Click the microphone to start transcribing your speech.",containerStyle:{borderRadius:"8px"},speechToText:{azure:{subscriptionKey:"key",region:"region",language:"en-US"}},mdxType:"DeepChatBrowser"})),(0,r.kt)(u.Z,{mdxType:"Tabs"},(0,r.kt)(p.Z,{value:"js",label:"Sample code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'<deep-chat\n  speechToText=\'{\n    "azure": {"subscriptionKey": "resource-key", "region": "resource-region", "language": "en-US"}\n  }\'\n></deep-chat>\n'))),(0,r.kt)(p.Z,{value:"py",label:"Full code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  speechToText=\'{\n    "azure": {"subscriptionKey": "resource-key", "region": "resource-region", "language": "en-US"}\n  }\'\n  introMessage="Click the microphone to start transcribing your speech."\n  containerStyle=\'{"borderRadius": "8px"}\'\n  directConnection=\'{"demo": true}\'\n></deep-chat>\n')))),(0,r.kt)(s.Z,{mdxType:"LineBreak"}),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("inlineCode",{parentName:"p"},"subscriptionKey")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"token")," properties should only be used for local/prototyping/demo purposes ONLY. When you are ready to deploy your application,\nplease switch to using the ",(0,r.kt)("inlineCode",{parentName:"p"},"retrieveToken")," property. Check out the example below and ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/OvidijusParsiunas/speech-to-element/tree/main/examples"},"starter server templates"),".")),(0,r.kt)(s.Z,{mdxType:"LineBreak"}),(0,r.kt)("h4",{id:"retrieve-token-example"},"Retrieve token example"),(0,r.kt)(o.Z,{mdxType:"ComponentContainer"},(0,r.kt)(i.Z,{directConnection:{demo:!0},introMessage:"Click the microphone to start transcribing your speech.",containerStyle:{borderRadius:"8px"},speechToText:{azure:{region:"resource-region",retrieveToken:async()=>fetch("http://localhost:8080/token").then((e=>e.text())).then((e=>e)).catch((e=>console.error("error")))}},mdxType:"DeepChatBrowser"})),(0,r.kt)(u.Z,{mdxType:"Tabs"},(0,r.kt)(p.Z,{value:"js",label:"Code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},"speechToText.speechToText = {\n  region: 'resource-region',\n  retrieveToken: async () => {\n    return fetch('http://localhost:8080/token')\n      .then((res) => res.text())\n      .then((token) => token);\n  },\n};\n")))),(0,r.kt)(s.Z,{mdxType:"LineBreak"}),(0,r.kt)("h3",{id:"TextColor"},(0,r.kt)("inlineCode",{parentName:"h3"},"TextColor")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Type: {",(0,r.kt)("inlineCode",{parentName:"li"},"interim?: string"),", ",(0,r.kt)("inlineCode",{parentName:"li"},"final?: string"),"}")),(0,r.kt)("p",null,"This object is used to set the color of ",(0,r.kt)("inlineCode",{parentName:"p"},"interim")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"final")," results text. ",(0,r.kt)("br",null)),(0,r.kt)("h4",{id:"example-4"},"Example"),(0,r.kt)(o.Z,{mdxType:"ComponentContainer"},(0,r.kt)(i.Z,{directConnection:{demo:!0},introMessage:"Send a message to hear the response.",containerStyle:{borderRadius:"8px"},speechToText:{textColor:{interim:"green",final:"blue"}},mdxType:"DeepChatBrowser"})),(0,r.kt)(u.Z,{mdxType:"Tabs"},(0,r.kt)(p.Z,{value:"js",label:"Sample code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'<deep-chat speechToText=\'{"textColor": {"interim": "green", "final": "blue"}}\'></deep-chat>\n'))),(0,r.kt)(p.Z,{value:"py",label:"Full code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  speechToText=\'{"textColor": {"interim": "green", "final": "blue"}}\'\n  introMessage="Send a message to hear the response."\n  containerStyle=\'{"borderRadius": "8px"}\'\n  directConnection=\'{"demo": true}\'\n></deep-chat>\n')))),(0,r.kt)(s.Z,{mdxType:"LineBreak"}),(0,r.kt)("h3",{id:"Commands"},(0,r.kt)("inlineCode",{parentName:"h3"},"Commands")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Type: {",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"p"},"stop?: string"),", ",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"p"},"pause?: string"),", ",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"p"},"resume?: string"),", ",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"p"},"removeAllText?: string"),", ",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"p"},"submit?: string"),", ",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"p"},"commandMode?: string"),", ",(0,r.kt)("br",null),"\n","\xa0","\xa0","\xa0","\xa0"," ",(0,r.kt)("inlineCode",{parentName:"p"},"settings?:")," {",(0,r.kt)("inlineCode",{parentName:"p"},"substrings?: boolean"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"caseSensitive?: boolean"),"} ",(0,r.kt)("br",null),"\n}")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Default: ",(0,r.kt)("em",{parentName:"p"},"{settings: {substrings: true, caseSensitive: false}}")))),(0,r.kt)("p",null,"This object is used to set the phrases which will control chat functionality via speech. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"stop")," is used to stop the speech service. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"pause")," will temporarily stop the transcription and will re-enable it after the phrase for ",(0,r.kt)("inlineCode",{parentName:"p"},"resume")," is spoken. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"removeAllText")," is used to remove all input text. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"submit")," will send the current input text. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"commandMode")," is a phrase that is used to activate the command mode which will not transcribe any text and will wait for a command to be executed. To leave\nthe command mode - you can use the phrase for the ",(0,r.kt)("inlineCode",{parentName:"p"},"resume")," command. ",(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"substrings")," is used to toggle whether command phrases can be part of spoken words or if they are whole words. E.g. when this is set to ",(0,r.kt)("em",{parentName:"p"},"true")," and your command phrase is ",(0,r.kt)("em",{parentName:"p"},'"stop"'),' -\nwhen you say "stopping" the command will be executed. However if it is set to ',(0,r.kt)("em",{parentName:"p"},"false"),' - the command will only be executed if you say "stop". ',(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"caseSensitive")," is used to toggle if command phrases are case sensitive. E.g. if this is set to ",(0,r.kt)("em",{parentName:"p"},"true")," and your command phrase is ",(0,r.kt)("em",{parentName:"p"},'"stop"'),' - when the service recognizes\nyour speech as "Stop" it will not execute your command. On the other hand if it is set to ',(0,r.kt)("em",{parentName:"p"},"false")," it will execute."),(0,r.kt)("h4",{id:"example-5"},"Example"),(0,r.kt)(o.Z,{mdxType:"ComponentContainer"},(0,r.kt)(i.Z,{directConnection:{demo:!0},introMessage:"Click the microphone to start transcribing your speech.",containerStyle:{borderRadius:"8px"},speechToText:{commands:{stop:"stop",pause:"pause",resume:"resume",removeAllText:"remove text",submit:"submit",commandMode:"command",settings:{substrings:!0,caseSensitive:!1}}},mdxType:"DeepChatBrowser"})),(0,r.kt)(u.Z,{mdxType:"Tabs"},(0,r.kt)(p.Z,{value:"js",label:"Sample code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'<deep-chat\n  speechToText=\'{\n    "commands": {\n      "stop": "stop",\n      "pause": "pause",\n      "resume": "resume",\n      "removeAllText": "remove text",\n      "submit": "submit",\n      "commandMode": "command",\n      "settings": {\n        "substrings": true,\n        "caseSensitive": false\n  }}}\'\n></deep-chat>\n'))),(0,r.kt)(p.Z,{value:"py",label:"Full code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  speechToText=\'{\n    "commands": {\n      "stop": "stop",\n      "pause": "pause",\n      "resume": "resume",\n      "removeAllText": "remove text",\n      "submit": "submit",\n      "commandMode": "command",\n      "settings": {\n        "substrings": true,\n        "caseSensitive": false\n  }}}\'\n  introMessage="Click the microphone to start transcribing your speech."\n  containerStyle=\'{"borderRadius": "8px"}\'\n  directConnection=\'{"demo": true}\'\n></deep-chat>\n')))),(0,r.kt)(s.Z,{mdxType:"LineBreak"}),(0,r.kt)("h3",{id:"ButtonStyles"},(0,r.kt)("inlineCode",{parentName:"h3"},"ButtonStyles")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Type: {",(0,r.kt)("a",{parentName:"li",href:"./styles/#ButtonStyles"},(0,r.kt)("inlineCode",{parentName:"a"},"commandMode?: ButtonStyles")),", ",(0,r.kt)("a",{parentName:"li",href:"./styles/#MicrophoneStyles"},(0,r.kt)("inlineCode",{parentName:"a"},"MicrophoneStyles")),"}")),(0,r.kt)("p",null,"This object is used to define the styling for the microphone button. ",(0,r.kt)("br",null),"\nIt contains the same properties as the ",(0,r.kt)("a",{parentName:"p",href:"./styles/#MicrophoneStyles"},(0,r.kt)("inlineCode",{parentName:"a"},"MicrophoneStyles"))," object\nand an additional ",(0,r.kt)("inlineCode",{parentName:"p"},"commandMode")," property which sets the button styling when the ",(0,r.kt)("a",{parentName:"p",href:"#Commands"},(0,r.kt)("inlineCode",{parentName:"a"},"command mode"))," is activated. ",(0,r.kt)("br",null)),(0,r.kt)("p",null,"// WORK - potentially include a pause style"),(0,r.kt)("h4",{id:"example-6"},"Example"),(0,r.kt)(o.Z,{mdxType:"ComponentContainer"},(0,r.kt)(i.Z,{directConnection:{demo:!0},introMessage:"Click the microphone to start transcribing your speech.",containerStyle:{borderRadius:"8px"},speechToText:{button:{commandMode:{svg:{styles:{default:{filter:"brightness(0) saturate(100%) invert(70%) sepia(70%) saturate(4438%) hue-rotate(170deg) brightness(92%) contrast(98%)"}}}},active:{svg:{styles:{default:{filter:"brightness(0) saturate(100%) invert(16%) sepia(48%) saturate(4810%) hue-rotate(347deg) brightness(110%) contrast(106%)"}}}},default:{svg:{styles:{default:{filter:"brightness(0) saturate(100%) invert(77%) sepia(9%) saturate(7093%) hue-rotate(32deg) brightness(99%) contrast(83%)"}}}}}},mdxType:"DeepChatBrowser"})),(0,r.kt)(u.Z,{mdxType:"Tabs"},(0,r.kt)(p.Z,{value:"js",label:"Sample code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'<deep-chat\n  speechToText=\'{\n    "button": {\n      "commandMode": {\n        "svg": {\n          "styles": {\n            "default": {\n              "filter":\n                "brightness(0) saturate(100%) invert(70%) sepia(70%) saturate(4438%) hue-rotate(170deg) brightness(92%) contrast(98%)"\n      }}}},\n      "active": {\n        "svg": {\n          "styles": {\n            "default": {\n              "filter":\n                "brightness(0) saturate(100%) invert(16%) sepia(48%) saturate(4810%) hue-rotate(347deg) brightness(110%) contrast(106%)"\n      }}}},\n      "default": {\n        "svg": {\n          "styles": {\n            "default": {\n              "filter":\n                "brightness(0) saturate(100%) invert(77%) sepia(9%) saturate(7093%) hue-rotate(32deg) brightness(99%) contrast(83%)"\n    }}}}}\n  }\'\n></deep-chat>\n'))),(0,r.kt)(p.Z,{value:"py",label:"Full code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  speechToText=\'{\n    "button": {\n      "commandMode": {\n        "svg": {\n          "styles": {\n            "default": {\n              "filter":\n                "brightness(0) saturate(100%) invert(70%) sepia(70%) saturate(4438%) hue-rotate(170deg) brightness(92%) contrast(98%)"\n      }}}},\n      "active": {\n        "svg": {\n          "styles": {\n            "default": {\n              "filter":\n                "brightness(0) saturate(100%) invert(16%) sepia(48%) saturate(4810%) hue-rotate(347deg) brightness(110%) contrast(106%)"\n      }}}},\n      "default": {\n        "svg": {\n          "styles": {\n            "default": {\n              "filter":\n                "brightness(0) saturate(100%) invert(77%) sepia(9%) saturate(7093%) hue-rotate(32deg) brightness(99%) contrast(83%)"\n    }}}}}\n  }\'\n  introMessage="Click the microphone to start transcribing your speech."\n  containerStyle=\'{"borderRadius": "8px"}\'\n  directConnection=\'{"demo": true}\'\n></deep-chat>\n')))),(0,r.kt)(s.Z,{mdxType:"LineBreak"}),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"You can use the ",(0,r.kt)("a",{parentName:"p",href:"https://cssfilterconverter.com/"},(0,r.kt)("inlineCode",{parentName:"a"},"CSSFilterConverter"))," tool to generate filter values for the icon color.")),(0,r.kt)(s.Z,{mdxType:"LineBreak"}),(0,r.kt)("p",null,"// WORK - test error handling for incorrect config"),(0,r.kt)("h2",{id:"demo"},"Demo"),(0,r.kt)("p",null,"This is the example used in the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/OvidijusParsiunas/deep-chat/assets/18709577/e103a42e-b3a7-4449-b9db-73fed6d7876e"},"demo video"),". When replicating - make sure\nto add the Speech SDK to your project and add your resource properties."),(0,r.kt)(o.Z,{mdxType:"ComponentContainer"},(0,r.kt)(i.Z,{directConnection:{demo:!0},containerStyle:{marginRight:"30px"},textToSpeech:!0,speechToText:{azure:{subscriptionKey:"resource-key",region:"resource-region"},commands:{submit:"submit",stop:"stop",removeAllText:"remove all text",pause:"pause",resume:"continue"}},mdxType:"DeepChatBrowser"}),(0,r.kt)(i.Z,{directConnection:{demo:!0},textToSpeech:!0,speechToText:{azure:{subscriptionKey:"resource-key",region:"resource-region"},commands:{submit:"submit",stop:"stop",removeAllText:"remove",pause:"pause",resume:"continue",commandMode:"belfast"}},mdxType:"DeepChatBrowser"})),(0,r.kt)(u.Z,{mdxType:"Tabs"},(0,r.kt)(p.Z,{value:"js",label:"Code",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<div style="display: flex">\n  <deep-chat\n    speechToText=\'{\n      "azure": {\n        "subscriptionKey": "resource-key",\n        "region": "resource-region"\n      },\n      "commands": {\n        "stop": "stop",\n        "pause": "pause",\n        "resume": "resume",\n        "removeAllText": "remove text",\n        "submit": "submit",\n        "commandMode": "command"\n    }}\'\n    containerStyle=\'{"marginRight": "30px"}\'\n    directConnection=\'{"demo": true}\'\n  ></deep-chat>\n  <deep-chat\n    speechToText=\'{\n      "commands": {\n        "azure": {\n          "subscriptionKey": "resource-key",\n          "region": "resource-region"\n        },\n        "stop": "stop",\n        "pause": "pause",\n        "resume": "resume",\n        "removeAllText": "remove text",\n        "submit": "submit",\n        "commandMode": "command"\n    }}\'\n    directConnection=\'{"demo": true}\'\n  ></deep-chat>\n</div>\n')))),(0,r.kt)(s.Z,{mdxType:"LineBreak"}))}y.isMDXComponent=!0}}]);